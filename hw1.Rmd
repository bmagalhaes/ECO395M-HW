---
title: "homework1"
author: "Bernardo Magalhaes, Adhish Luitel, Ji Heon Shim"
date: "`r format(Sys.Date())`" 
output:
  md_document:
    variant: markdown_github
---
By Bernardo Magalhaes, Adhish Luitel, Ji Heon Shim
# Exercise 1

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mosaic)
library(ggplot2)
library(FNN)

#setup
urlfile<-'https://raw.githubusercontent.com/bmagalhaes/ECO395M-HW/master/abia.csv'
abia<-read.csv(url(urlfile))
```

## Exercise 1.1
In this question, we have all the data of flight information that arrive at or depart from Austin-Berstrom airport.  

```{r 1.1.1, echo=FALSE}
abia = mutate(abia, category = ifelse(Origin == "AUS", "Departure", "Arrival"))
abia$CRSTWindow_D = floor(abia$CRSDepTime/100)
abia$CRSTWindow_A = floor(abia$CRSArrTime/100)
us_states <- map_data("state")
urlfile<-'https://raw.githubusercontent.com/bmagalhaes/ECO395M-HW/master/airports.csv'
airports = read.csv(url(urlfile))
airports = subset(airports,!(airports$iata_code == ""))
airports = airports[-c(1:4,7:13,15:18)]

abia_conf <- subset(abia,(abia$Cancelled == "0"))
abia_conf <- subset(abia_conf,!(abia_conf$Diverted == 1)) 
abia_cancel <- subset(abia,(abia$Cancelled == "1"))

```

### Which airline company has the highest cancellation rate?
First, we'll have a close look on cancellation rates by airline companies. Our data shows that American Eagle airline(MQ) has the highest cancellation rate among all the airlines flying through Austin.

```{r 1.1.2, echo=FALSE, warning=FALSE}
departures_fly <- subset(abia_conf, abia_conf$category == "Departure")
  delay_summ = departures_fly %>%
    group_by(Dest)  %>%  # group the data points by model nae
    summarize(dly.mean = mean(DepDelay[(DepDelay>=0)], na.rm=TRUE))
  delay_summ = left_join(delay_summ, airports, by = c("Dest" = "iata_code"))
  delay_summ = mutate(delay_summ,AUSLat = 30.194500)
  delay_summ = mutate(delay_summ,AUSLong = -97.66990)

cancel_rate = abia %>%
  group_by(UniqueCarrier)  %>%  # group the data points by model nae
  summarize(cancelrate = length(which(Cancelled == 1)) / (length(which(Cancelled == 1)) + length(which(Cancelled == 0))))
cancel_rate = mutate(cancel_rate,cancelrate = cancelrate*100)

ggplot(cancel_rate, aes(x=reorder(UniqueCarrier, cancelrate), y=cancelrate)) + 
  geom_bar(stat='identity') + 
  coord_flip() +
  labs(title = 'Cancellation Rate per Carrier', x = "Carrier", y = "Cancellation Rate (%)")+
  scale_size_area()+
  theme(plot.title = element_text(hjust = 0.5))
```

### Which destination is likely to cause the longest departure delay?
Next, we examined all the aircrafts departing from Austin, and arranged departure delays by their destinations. Our analysis shows that DTW(Detroit) is the destination which causes the most departure delay from Austin.

```{r 1.1.3, echo=FALSE, warning=FALSE}
ggplot(delay_summ, aes(x=reorder(Dest, dly.mean), y=dly.mean)) + 
  geom_bar(stat='identity') + 
  coord_flip() +
  labs(title = 'Average Departure Delay per Destination', x = "Airport", y = "Minutes") +
  scale_size_area()+
  theme(plot.title = element_text(hjust = 0.5))
```

### What time of day does flight delay mostly occur?
Next, we arranged our departure delay data by scheduled departure time. Our analysis shows that departure delays are most likely to happen between 0 to 1 o'clock at midnight. We don't know the exact reason for this, but bad sight due to darkness can be one of various reasons which cause departure delays.

```{r 1.1.4, echo=FALSE}
# plot the summ for all the airline companies 
abia_CRSsumm_D_total <- abia_conf %>%
  group_by(CRSTWindow_D,category) %>%
  summarise(DepDelay_mean = mean(DepDelay))

abia_CRSsumm_A_total <- abia_conf %>%
  group_by(CRSTWindow_A,category) %>%
  summarise(ArrDelay_mean = mean(ArrDelay))

ggplot(data = subset(abia_CRSsumm_D_total,(abia_CRSsumm_D_total$category == "Departure")))+
  geom_bar(aes(x = CRSTWindow_D, y = DepDelay_mean),stat='identity',position='dodge')+
  labs(title = "Scheduled Time vs Average Departure Delay", x = "Scheduled Time", y = "Departure Delay")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5), panel.grid.major = element_blank())
```

Now, we arranged our arrival delay data by scheduled arrival time. Our analysis shows that arrival delays are most likely to happen between 22 to 23 o'clock at night. Again, we can guess that bad sight due to darkness can be one of various reasons.
```{r 1.1.5, echo=FALSE}
ggplot(data = subset(abia_CRSsumm_A_total,(abia_CRSsumm_A_total$category == "Arrival")))+
  geom_bar(aes(x = CRSTWindow_A, y = ArrDelay_mean),stat='identity',position='dodge')+
  labs(title = "Scheduled Time vs Average Arrival Delay", x = "Scheduled Time", y = "Arrival Delay")+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))
```

### Which month of year does flight delay mostly to occur?
This time, we'll extend our view from day to year to find out the month which flight delay mostly occurs. In case of departure delays from Austin, December is the worst month if someone wants to avoid any delays. If you depart from Austin in December, you'll expect more than 15 minutes of delay on average.

```{r 1.1.6, echo=FALSE}
# plot the summ for all the airline companies 
abia_summ_Month <- abia_conf %>%
  group_by(Month,category) %>%
  summarise(DepDelay_mean = mean(DepDelay),ArrDelay_mean = mean(ArrDelay))

ggplot(data = subset(abia_summ_Month,(abia_summ_Month$category == "Departure")))+
  geom_bar(aes(x = Month, y = DepDelay_mean),stat='identity',position='dodge')+
  labs(title = "Month vs Average Departure Delay", x = "Month", y = "Departure Delay")+
  theme_bw()+
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12),labels = c("1" = "Jan", "2" = "Feb", "3" = "Mar", "4" = "Apr", "5" = "May", "6" = "Jun", "7" = "Jul", "8" = "Aug", "9" = "Sep", "10" = "Oct", "11" = "Nov", "12" = "Dec"))+
  theme(plot.title = element_text(hjust = 0.5))
```

December is the worst month again to avoid delays in case of arrival, too. It is likely to be caused by lots of flight demands at the end of year.

```{r 1.1.7, echo=FALSE}
ggplot(data = subset(abia_summ_Month,(abia_summ_Month$category == "Arrival")))+
  geom_bar(aes(x = Month, y = ArrDelay_mean),stat='identity',position='dodge')+
  labs(title = "Month vs Average Arrival Delay", x = "Month", y = "Arrival Delay")+
  scale_x_continuous(breaks = c(1,2,3,4,5,6,7,8,9,10,11,12),labels = c("1" = "Jan", "2" = "Feb", "3" = "Mar", "4" = "Apr", "5" = "May", "6" = "Jun", "7" = "Jul", "8" = "Aug", "9" = "Sep", "10" = "Oct", "11" = "Nov", "12" = "Dec"))+
  theme_bw()+
  theme(plot.title = element_text(hjust = 0.5))
```

### Which airline company shows the longest delay time?

Now, we'll see which airline company shows the longest delay time. In case of departure delays, ExpressJet airlines(EV) shows the worst performance among all the airlines. The boxplot below shows that EV has the largest median and variance. And the barplot also shows that average departure delay time is the longest in EV.

```{r 1.1.8, echo=FALSE}
bwplot(DepDelay~UniqueCarrier, data=abia_conf, ylim=c(-20,60), xlab="Airlines", ylab="Departure delays(min)", main="Departure delays by Airlines")
AvgDepDelay_Unique=abia_conf%>% group_by(UniqueCarrier) %>% summarize(AvgDepDelay= mean(DepDelay) )

mean.abia_conf<-as.data.frame(tapply(abia_conf$DepDelay, abia_conf$UniqueCarrier, mean))
mean.abia_conf$UniqueCarrier<-rownames(mean.abia_conf)
names(mean.abia_conf)<-c("DepDelay","UniqueCarrier")
ggplot(mean.abia_conf, aes(reorder(UniqueCarrier, -DepDelay, sum), DepDelay))+geom_bar(stat="identity")+labs(title = "Average departure delay by Airlines", x = "Airlines", y = "Average departure delay(min)")
```

In case of arrival delays, the box plot apparently gives us information that PSA airline(OH) seems to have the highest median and also unstable delay range by large variance. The barplot below confirms this idea by showing the largest average arrival delay time for OH.

```{r 1.1.9, echo=FALSE}
bwplot(ArrDelay~UniqueCarrier, data=abia_conf, ylim=c(-60,70), xlab="Airlines", ylab="Arrival delays(min)", main="Arrival delays by Airlines")
AvgDepDelay_Unique=abia_conf%>% group_by(UniqueCarrier) %>% summarize(AvgArrDelay= mean(ArrDelay) )

mean.abia_conf<-as.data.frame(tapply(abia_conf$ArrDelay, abia_conf$UniqueCarrier, mean))
mean.abia_conf$UniqueCarrier<-rownames(mean.abia_conf)
names(mean.abia_conf)<-c("ArrDelay","UniqueCarrier")
ggplot(mean.abia_conf, aes(reorder(UniqueCarrier, -ArrDelay, sum), ArrDelay))+geom_bar(stat="identity")+labs(title = "Average arrival delay by Airlines", x = "Airlines", y = "Average arrival delay(min)")

```

(text)

```{r 1.1.10, echo=FALSE}
# delay_summ$dly.mean[is.nan(delay_summ$dly.mean)]<-0.01
# delay_summ = subset(delay_summ,(delay_summ$dly.mean >= 1))
# delay_summ = arrange(delay_summ, dly.mean)


ggplot() +
  theme(plot.title = element_text(hjust = 0.5), panel.grid.major = element_blank(),  panel.grid.minor = element_blank())+
  geom_polygon(data = us_states,  aes(long, lat, group = group), fill = "grey", col = "black") +
  geom_curve(data=delay_summ, aes(x = AUSLong, y = AUSLat, xend = longitude_deg, yend = latitude_deg, colour = dly.mean), size = 1, curvature = 0.1) + 
  geom_point(data=delay_summ, aes(x=longitude_deg, y=latitude_deg),color="red",size=1) +
  scale_colour_gradient2(low="blue", high="red")+
  labs(title = 'Average Departure Delay per Destination', x = "", y = "")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_discrete()+
  scale_y_discrete()
```

(text)

```{r 1.1.11, echo=FALSE}
summary(delay_summ$dly.mean)
delay_quant = subset(delay_summ,delay_summ$dly.mean >= 30.2)
ggplot() +
  theme(plot.title = element_text(hjust = 0.5), panel.grid.major = element_blank(),  panel.grid.minor = element_blank())+
  geom_polygon(data = us_states,  aes(long, lat, group = group), fill = "grey", col = "black") +
  geom_curve(data=delay_quant, aes(x = AUSLong, y = AUSLat, xend = longitude_deg, yend = latitude_deg, colour = dly.mean), size = 1, curvature = 0.1) + 
  geom_point(data=delay_quant, aes(x=longitude_deg, y=latitude_deg),color="red",size=1) +
  scale_colour_gradient2(low="blue", high="red")+
  labs(title = 'Average Departure Delay per Destination - 3rd Quantile', x = "", y = "")+
  theme(plot.title = element_text(hjust = 0.5))+
  scale_x_discrete()+
  scale_y_discrete()
#  transition_states(dly.mean, transition_length = 0, state_length = 1)
```


```{r setup2, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
urlfile<-'https://raw.githubusercontent.com/bmagalhaes/ECO395M-HW/master/sclass.csv'
sclass<-read.csv(url(urlfile))
```

# Exercise 1.2
We used K-nearest neighbors to build a predictive model for price, given mileage, separately for each of two trim levels: 350 and 65 AMG.  In order to do this, we divided our data into 2 subgroups, 350 and 65 AMG, and got rid of all the other data.

```{r 1.2.1, echo=FALSE}
# Divide groups into 2 and define 'Root Mean Squre Error' function
sclass_350 <- subset(sclass,(sclass$trim == "350"))
sclass_65AMG <- subset(sclass,(sclass$trim == "65 AMG"))
rmse = function(y, ypred) {
  sqrt(mean(data.matrix((y-ypred)^2)))
}
```

### Sclass 350
First, we'll look on the Sclass 350 data. We can see there's a negative relationship between mileage and price plotted as below  


```{r 1.2.2, echo=FALSE}
# plot the data
p_350 = ggplot(data = sclass_350) + 
  geom_point(mapping = aes(x = mileage, y = price), color='medium purple')+
  theme_bw()+
  labs(title = "Mileage vs Price (Sclass 350)")+
  theme(plot.title = element_text(hjust = 0.5))
p_350
```

And we splitted Sclass 350 data into two groups. One is "training set", and the other is "test set". The training set accounts for 80% of whole data. 

```{r 1.2.3, echo=FALSE}
# Make a train-test split
N = nrow(sclass_350)
N_train = floor(0.8*N)
N_test = N - N_train

# randomly sample a set of data points to include in the training set
train_ind = sample.int(N, N_train, replace=FALSE)

# Define the training and testing set
D_train = sclass_350[train_ind,]
D_test = sclass_350[-train_ind,]

# optional book-keeping step:
D_test = arrange(D_test, mileage)

# Now separate the training and testing sets into features (X) and outcome (y)
X_train = select(D_train, mileage)
y_train = select(D_train, price)
X_test = select(D_test, mileage)
y_test = select(D_test, price)

```

Then we ran K-nearest-neighbors for k, starting from k=3 to higher value. We faced an error when k=2, so the possible minimum value of k was 3. The fitted model for k=3 is as below, and RSME is 10880.2
  
```{r 1.2.4, echo=FALSE}
# k=3
knn3 = knn.reg(train = X_train, test = X_test, y = y_train, k=3)
ypred_knn3 = knn3$pred
D_test$ypred_knn3 = ypred_knn3

p_test_knn3 = ggplot(data = D_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  geom_path(mapping = aes(x = mileage, y = ypred_knn3), color='red') +
  theme_bw()+
  labs(title = "Fitted Model for k=3 (Sclass 350)")+
  theme(plot.title = element_text(hjust = 0.5))
p_test_knn3
rmse(y_test, ypred_knn3)
```

When k=20, The fitted model is as below. RSME is 9238.5, which is smaller than RSME when k=3. 


```{r 1.2.5, echo=FALSE}
# k=20
knn20 = knn.reg(train = X_train, test = X_test, y = y_train, k=20)
ypred_knn20 = knn20$pred

D_test$ypred_knn20 = ypred_knn20

p_test_knn20 = ggplot(data = D_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  geom_path(mapping = aes(x = mileage, y = ypred_knn20), color='red') +
  theme_bw()+
  labs(title = "Fitted Model for k=20 (Sclass 350)")+
  theme(plot.title = element_text(hjust = 0.5))
p_test_knn20
rmse(y_test, ypred_knn20)
```

Now, the fitted model for k=100 below shows us the fact that the graph gets smoother as k goes bigger. But RSME when k=100 is 10483.9, which is bigger than that of when k=20. So it is probable that the optimal k that minimizes RSME will be somewhere between k=3 and k=100.


```{r 1.2.6, echo=FALSE}
# k=100
knn100 = knn.reg(train = X_train, test = X_test, y = y_train, k=100)
ypred_knn100 = knn100$pred

D_test$ypred_knn100 = ypred_knn100

p_test_knn100 = ggplot(data = D_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  geom_path(mapping = aes(x = mileage, y = ypred_knn100), color='red') +
  theme_bw()+
  labs(title = "Fitted Model for k=100 (Sclass 350)")+
  theme(plot.title = element_text(hjust = 0.5))
p_test_knn100
rmse(y_test, ypred_knn100)
```

In order to find the optimal k, we plotted k versus RSME for every k. The graph below shows that RSME is minimized to 9134.4 when k equals to 18.   
The optimal value of k can vary whenever we run the regression because samples are randomly chosen.


```{r 1.2.7, echo=FALSE}
KNN_result <- data.frame(K=c(), rsme=c())
# KNN
for(v in c(3:nrow(X_train))){
  knn_K = knn.reg(train = X_train, test = X_test, y = y_train, k=v)
  ypred_knn = knn_K$pred
  KNN_rsme = rmse(y_test, ypred_knn)
  KNN_result <- rbind(KNN_result,c(v,KNN_rsme))
}

colnames(KNN_result) = c("K","RSME")
Kmin = KNN_result$K[which.min(KNN_result$RSME)]

P_KNNresult_350 = ggplot(data = KNN_result)+
  geom_line(aes(x = K, y = RSME))+
  geom_line(aes(x = Kmin, y = RSME), col = "red")+
  theme_bw()+
  labs(title = "K vs RSME(Sclass 350)")+
  theme(plot.title = element_text(hjust = 0.5))
P_KNNresult_350
Kmin
knn_kmin = knn.reg(train = X_train, test = X_test, y = y_train, k=Kmin)
ypred_knn_kmin = knn_kmin$pred
D_test$ypred_knn_kmin = ypred_knn_kmin
rmse(y_test, ypred_knn_kmin)
```

The graph below shows the plot of the fitted value when k is the optimal value.

```{r 1.2.8, echo=FALSE}
p_test_knn_kmin = ggplot(data = D_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  geom_path(mapping = aes(x = mileage, y = ypred_knn_kmin), color='red') +
  theme_bw()+
  labs(title = "Fitted Model for k=18 (Optimal, Sclass 350)")+
  theme(plot.title = element_text(hjust = 0.5))
p_test_knn_kmin
```
### Sclass 65 AMG
Now, we'll take the same step to find out the optimal k for subgroup sclass 65 AMG. The plot below also shows us a negative relation between price and mileage.

```{r 1.2.9, echo=FALSE}
# plot the data
p_65 = ggplot(data = sclass_65AMG) + 
  geom_point(mapping = aes(x = mileage, y = price), color='salmon 3')+
  theme_bw()+
  labs(title = "Mileage vs Price (Sclass 65 AMG)")+
  theme(plot.title = element_text(hjust = 0.5))
p_65
```

As we did on the Sclass 350 case, the Sclass 65 AMG data is also splitted into two groups- a training set and a test set. The training set accounts for 80% of whole data. 

```{r 1.2.10, echo=FALSE}
# Make a train-test split
N = nrow(sclass_65AMG)
N_train = floor(0.8*N)
N_test = N - N_train

# randomly sample a set of data points to include in the training set
train_ind = sample.int(N, N_train, replace=FALSE)

# Define the training and testing set
D_train = sclass_65AMG[train_ind,]
D_test = sclass_65AMG[-train_ind,]

# optional book-keeping step:
D_test = arrange(D_test, mileage)

# Now separate the training and testing sets into features (X) and outcome (y)
X_train = select(D_train, mileage)
y_train = select(D_train, price)
X_test = select(D_test, mileage)
y_test = select(D_test, price)
```

We'll start with k=3, and run K-nearest-neighbors. The fitted model for k=3 is as below, and RSME is 21822.8

```{r 1.2.11, echo=FALSE}
# k=3
knn3 = knn.reg(train = X_train, test = X_test, y = y_train, k=3)
ypred_knn3 = knn3$pred
D_test$ypred_knn3 = ypred_knn3

p_test_knn3 = ggplot(data = D_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  geom_path(mapping = aes(x = mileage, y = ypred_knn3), color='red') +
  theme_bw()+
  labs(title = "Fitted Model for k=3 (Sclass 65 AMG)")+
  theme(plot.title = element_text(hjust = 0.5))
p_test_knn3
rmse(y_test, ypred_knn3)
```

When k=20, The fitted model is as below. RSME is 22546.5, which is slightly bigger than RSME when k=3. 


```{r 1.2.12, echo=FALSE}
# k=20
knn20 = knn.reg(train = X_train, test = X_test, y = y_train, k=20)
ypred_knn20 = knn20$pred

D_test$ypred_knn20 = ypred_knn20

p_test_knn20 = ggplot(data = D_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  geom_path(mapping = aes(x = mileage, y = ypred_knn20), color='red') +
  theme_bw()+
  labs(title = "Fitted Model for k=20 (Sclass 65 AMG)")+
  theme(plot.title = element_text(hjust = 0.5))
p_test_knn20
rmse(y_test, ypred_knn20)
```
Now, the fitted model for k=100 below shows us the fact that the graph gets smoother as k goes bigger. But RSME when k=100 is 40928.0, which is much bigger than that of when k=20. So the optimal k that minimizes RSME must be much smaller than 100.

```{r 1.2.13, echo=FALSE}
# k=100
knn100 = knn.reg(train = X_train, test = X_test, y = y_train, k=100)
ypred_knn100 = knn100$pred

D_test$ypred_knn100 = ypred_knn100

p_test_knn100 = ggplot(data = D_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  geom_path(mapping = aes(x = mileage, y = ypred_knn100), color='red') +
  theme_bw()+
  labs(title = "Fitted Model for k=100 (Sclass 65 AMG)")+
  theme(plot.title = element_text(hjust = 0.5))
p_test_knn100
rmse(y_test, ypred_knn100)
```

In order to find the optimal k, we plotted k versus RSME for every k value. The graph below shows that RSME is minimized to 21037.7 when k equals to 4.

```{r 1.2.14, echo=FALSE}
KNN_result <- data.frame(K=c(), rsme=c())
# KNN
for(v in c(3:nrow(X_train))){
  knn_K = knn.reg(train = X_train, test = X_test, y = y_train, k=v)
  ypred_knn = knn_K$pred
  KNN_rsme = rmse(y_test, ypred_knn)
  KNN_result <- rbind(KNN_result,c(v,KNN_rsme))
}

colnames(KNN_result) = c("K","RSME")
Kmin = KNN_result$K[which.min(KNN_result$RSME)]

P_KNNresult_65AMG = ggplot(data = KNN_result)+
  geom_line(aes(x = K, y = RSME))+
  geom_line(aes(x = Kmin, y = RSME), col = "red")+
  theme_bw()+
  labs(title = "K vs RSME(Sclass 65 AMG)")+
  theme(plot.title = element_text(hjust = 0.5))
P_KNNresult_65AMG
Kmin
knn_kmin = knn.reg(train = X_train, test = X_test, y = y_train, k=Kmin)
ypred_knn_kmin = knn_kmin$pred
D_test$ypred_knn_kmin = ypred_knn_kmin
rmse(y_test, ypred_knn_kmin)

```

The graph below shows the plot of fitted model when k is optimally chosen. 

```{r 1.2.15, echo=FALSE}
p_test_knn_kmin = ggplot(data = D_test) + 
  geom_point(mapping = aes(x = mileage, y = price), color='lightgrey') + 
  geom_path(mapping = aes(x = mileage, y = ypred_knn_kmin), color='red') +
  theme_bw()+
  labs(title = "Fitted Model for k=4 (Optimal, Sclass 65 AMG)")+
  theme(plot.title = element_text(hjust = 0.5))
p_test_knn_kmin
```

In conclusion, the optimal k value was larger in subgroup Sclass 350 than sclass 65 AMG.   
There are more samples in 350 than in 65 AMG. So higher k can be required to get more precise prediction.
Besides, samples in 350 are more dispersed than those in 65 AMG. The large variance of sample can be one factor which requires high value of k.


```{r 1.2.16, echo=TRUE}
count(sclass_350)
count(sclass_65AMG)
```
